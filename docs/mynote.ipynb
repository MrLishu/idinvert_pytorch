{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.inverter import StyleGANInverter\n",
    "from models.face_landmark_detector import FaceLandmarkDetector\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "\n",
    "inverter = StyleGANInverter('styleganinv_ffhq256', learning_rate=0.01, iteration=100,\n",
    "                            reconstruction_loss_weight=1.0, perceptual_loss_weight=5e-5, regularization_loss_weight=0)\n",
    "generator = inverter.G\n",
    "resolution = inverter.G.resolution\n",
    "\n",
    "def align(image_name):\n",
    "    face_landmark_detector = FaceLandmarkDetector(resolution)\n",
    "    face_infos = face_landmark_detector.detect(os.path.join('images', image_name))[0]\n",
    "    image = face_landmark_detector.align(face_infos)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "source_image_name = 'female.png'\n",
    "source_image = align(source_image_name)\n",
    "source_image_code = inverter.easy_invert(source_image, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_id = 'all'\n",
    "layer_dict = {'all': list(range(generator.net.num_layers)), 'low': [0, 1], 'mid': [2, 3, 4, 5], 'high': list(range(6, 14))}\n",
    "layers = layer_dict[layer_id]\n",
    "\n",
    "weights = []\n",
    "for layer in layers:\n",
    "    weights.append(generator.net.synthesis.__getattr__(f'layer{layer}').epilogue.style_mod.dense.fc.weight.T.cpu().detach().numpy())\n",
    "weight = np.concatenate(weights, axis=1).astype(np.float32)\n",
    "weight = weight / np.linalg.norm(weight, axis=0, keepdims=True)\n",
    "eigen_values, eigen_vectors = np.linalg.eig(weight.dot(weight.T))\n",
    "\n",
    "boundary = eigen_vectors[0]\n",
    "new_codes = source_image_code.repeat(9, axis=0).reshape(9, generator.net.num_layers, -1)\n",
    "new_codes[:, layers, :] += boundary.reshape(1, 1, -1) * np.linspace(-3, 3, 9, dtype=np.float32).reshape(-1, 1, 1)\n",
    "new_images = generator.easy_synthesize(new_codes, latent_space_type='wp')['image']\n",
    "\n",
    "plt.figure(figsize=(19.2, 10.8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(f\"Images\")\n",
    "plt.imshow(np.concatenate(new_images, axis=1))\n",
    "plt.show()"
   ]
  }
 ]
}